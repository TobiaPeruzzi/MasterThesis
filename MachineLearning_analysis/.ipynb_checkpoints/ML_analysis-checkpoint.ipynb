{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 0]\n",
    "\n",
    "**Importing modules and setting up random seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, preprocessing\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 1055717\n",
    "np.random.seed(ID)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 1]\n",
    "\n",
    "**Loading data and splitting into train, validation and test subsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and labels from csv table containing interpolated spectra of type 1, 2 and intermediate\n",
    "df = pd.read_csv('/home/tobia/PycharmProjects/AGN_spectra/table_data_final.csv')\n",
    "data = df.loc[:, df.columns != 'labels']\n",
    "data_labels = df['labels']\n",
    "columns_wave = df.columns[:-1]\n",
    "\n",
    "# converts data and labels pandasdataframe into numpy arrays\n",
    "data = data.to_numpy()\n",
    "data_labels = data_labels.to_numpy()\n",
    "\n",
    "# check number of samples for every label\n",
    "sample_labels, sample_freqs = np.unique(data_labels, return_counts=True)\n",
    "print(\"Labels in dataset: \", sample_labels)\n",
    "print(\"Frequencies in dataset: \", sample_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into train, validation and test sets\n",
    "X_train, y_train, X_validation, y_validation, X_test, y_test = utils.subset_creation(data, data_labels)\n",
    "\n",
    "# check if every label is present in the training set\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 1.1]\n",
    "\n",
    "**Data preprocessing: feature scaling and mean normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: feature scaling and mean normalization\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 1.2]\n",
    "\n",
    "**Hyperparameters optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters optimization with random search. (Impiega svariati minuti)\n",
    "\n",
    "parameters={'C': scipy.stats.uniform(scale=10**5), 'gamma': scipy.stats.uniform(scale=10**5),\n",
    "            'kernel': ['linear', 'rbf'], 'class_weight':['balanced', None]}\n",
    "\n",
    "hyperparam_clf = svm.SVC(C=parameters['C'], kernel=parameters['kernel'], gamma=parameters['gamma'],\n",
    "                         class_weight=parameters['class_weight'])\n",
    "\n",
    "best_param, CVresults = utils.randomsearch_cv(parameters, hyperparam_clf, X_train, y_train, num_iter=68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 2]\n",
    "\n",
    "**SVM classification with various kernels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LINEAR KERNEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'linear' kernel\n",
    "con_mat, norm_con_mat, SVM_clf_lin, predictions = utils.SVM_clf(X_train, y_train,\n",
    "                                                                X_validation, y_validation,\n",
    "                                                                clf_C=0.07, weights='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RBF KERNEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rbf' kernel\n",
    "con_mat, norm_con_mat, SVM_clf_rbf = utils.SVM_clf(X_train, y_train, X_validation, y_validation, clf_C=34, clf_gamma=0.003,\n",
    "                                     clf_kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEGREE 2 POLYNOMIAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'poly2' kernel\n",
    "con_mat, norm_con_mat, SVM_clf_poly2 = utils.SVM_clf(X_train, y_train, X_validation, y_validation, clf_C=34, clf_gamma=0.003,\n",
    "                                     clf_kernel='poly', clf_degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEGREE 3 POLYNOMIAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'poly3' degree\n",
    "con_mat, norm_con_mat, SVM_clf_poly3 = utils.SVM_clf(X_train, y_train, X_validation, y_validation, clf_C=34, clf_gamma=0.003,\n",
    "                                     clf_kernel='poly', clf_degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 2.1]\n",
    "\n",
    "**Saliency map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_validation)):\n",
    "    if y_validation[i]==3 and class_prob[i,0]>0.50:\n",
    "        print(i)\n",
    "        break\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saliency map for linear SVM\n",
    "i_th_sample = 159\n",
    "saliency_map, class_prob = utils.saliency_map(SVM_clf_lin, X_validation, i_th_sample, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction probability for\", i_th_sample, \"sample in validation: \\n\")\n",
    "print(\"[Type 1, Type 2, Intermediate] \\n\")\n",
    "print(class_prob[i_th_sample], \"\\n\")\n",
    "print(\"Ground truth for\" , i_th_sample, \"sample in validation subset: \", y_validation[i_th_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color coding\n",
    "color_codes = utils.color_coding(saliency_map, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saliency map for every class\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(columns_wave, saliency_map[0], c='limegreen', label='Type 1 vs rest')\n",
    "plt.plot(columns_wave, saliency_map[1], c='orangered', label='Type 2 vs rest')\n",
    "plt.plot(columns_wave, saliency_map[2], c='dodgerblue', label='Int vs rest')\n",
    "plt.grid(axis='x', linestyle='--', linewidth=2, alpha=0.4)\n",
    "# i punti indicati in x sono (da destra): h beta, gamma, delta, zeta\n",
    "plt.xticks([0, 104, 242, 398, 736, 800, 831], rotation=70)\n",
    "plt.xlabel('Angstrom')\n",
    "plt.ylabel('Confidence derivative')\n",
    "plt.legend()\n",
    "#plt.savefig('saliency_maps/type2_goodclassification/type2_sal.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(columns_wave, X_validation[262,:])\n",
    "plt.grid(axis='x', linestyle='--', linewidth=2)\n",
    "plt.xticks([0, 104, 242, 398, 736, 800, 831], rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saliency map scatter plot for every class\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(columns_wave, saliency_map[0], c='limegreen', alpha=0.5, marker='o', s=70, label='Type 1 vs rest')\n",
    "plt.scatter(columns_wave, saliency_map[1], c='orangered', alpha=0.5, marker='o', s=70, label='Type 2 vs rest')\n",
    "plt.scatter(columns_wave, saliency_map[2], c='dodgerblue', alpha=0.5, marker='o', s=70, label='Int vs rest')\n",
    "plt.grid(axis='x', linestyle='--', linewidth=2)\n",
    "# i punti indicati in x sono (da destra): h beta, gamma, delta, zeta\n",
    "plt.xticks([0, 104, 242, 398, 736, 800, 831], rotation=70)\n",
    "plt.xlabel('Angstrom')\n",
    "plt.ylabel('Confidence derivative')\n",
    "plt.legend()\n",
    "#plt.savefig('saliency_maps/good_classification/type1_sal_good.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color coding for type 1 vs rest \n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(columns_wave, saliency_map[0], c=color_codes[0], cmap='coolwarm', s=5)\n",
    "plt.grid(axis='x', linestyle='--', linewidth=2)\n",
    "# i punti indicati in x sono (da destra): h beta, gamma, delta, zeta\n",
    "plt.xticks([104, 243, 398, 736])\n",
    "plt.xlabel('Wavelengths')\n",
    "plt.ylabel('Confidence derivative')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color coding for type 2 vs rest\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(columns_wave, saliency_map[1], c=color_codes[1], cmap='coolwarm', s=5)\n",
    "plt.grid(axis='x', linestyle='--', linewidth=2)\n",
    "# i punti indicati in x sono (da destra): h beta, gamma, delta, zeta\n",
    "plt.xticks([104, 243, 398, 736])\n",
    "plt.xlabel('Wavelengths')\n",
    "plt.ylabel('Confidence derivative')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color coding for type int vs rest\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(columns_wave, saliency_map[2], c=color_codes[2], cmap='coolwarm', s=5)\n",
    "plt.grid(axis='x', linestyle='--', linewidth=2)\n",
    "# i punti indicati in x sono (da destra): h beta, gamma, delta, zeta\n",
    "plt.xticks([104, 243, 398, 736])\n",
    "plt.xlabel('Wavelengths')\n",
    "plt.ylabel('Confidence derivative')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 3]\n",
    "\n",
    "**t-SNE dimensionality reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 3.1]\n",
    "\n",
    "**t-SNE for type 1 and type 2 AGN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and labels from csv table containing interpolated spectra of only type 1 and 2\n",
    "\n",
    "df = pd.read_csv('/home/tobia/PycharmProjects/AGN_spectra/table_data_type_1_and_2.csv')\n",
    "data = df.loc[:, df.columns != 'labels']\n",
    "data_labels = df['labels']\n",
    "\n",
    "# converts data and labels pandasdataframe into numpy arrays\n",
    "data = data.to_numpy()\n",
    "data_labels = data_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used only for t-sne\n",
    "\n",
    "# Feature scaling and mean normalization.\n",
    "# This can be used only for t-SNE, but is not strictly required.\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    average = np.mean(data[:,i])\n",
    "    stddev = np.std(data[:,i])\n",
    "    for j in range(data.shape[0]):\n",
    "        data[j,i] = np.around((data[j,i]-average)/stddev, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE dimensionality reduction\n",
    "\n",
    "X_embedded = utils.TSNE_dim_reduction(data, perp=50, components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only type 1 and type 2\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "agn_classes = ['Type 1', 'Type 2']\n",
    "\n",
    "scatter = plt.scatter(X_embedded[:,0], X_embedded[:,1], c=data_labels, cmap='plasma', alpha=0.5,\n",
    "                      marker='o', s=70)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=agn_classes)\n",
    "\n",
    "# Save figure\n",
    "#plt.savefig('tsne_figures/tSNE_perp40.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 3.2]\n",
    "\n",
    "**t-SNE for whole dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data and labels for t-SNE\n",
    "\n",
    "df = pd.read_csv('/home/tobia/PycharmProjects/AGN_spectra/table_data_final.csv')\n",
    "\n",
    "# divide data in type 1, 2 and intermediate to get same colors in t-SNE plots\n",
    "s1_data = df.loc[:679, df.columns != 'labels']\n",
    "s2_data = df.loc[680:2824, df.columns != 'labels']\n",
    "int_data = df.loc[2825:, df.columns != 'labels']\n",
    "\n",
    "# same for labels\n",
    "data_targets = df['labels']\n",
    "s1_labels = data_targets[:680]\n",
    "s2_labels = data_targets[680:2825]\n",
    "int_labels = data_targets[2825:]\n",
    "s1_labels = s1_labels - 1\n",
    "int_labels = int_labels - 2\n",
    "\n",
    "# stack single data an labels type\n",
    "data_labels = np.hstack((s1_labels, np.hstack((int_labels, s2_labels))))\n",
    "data = np.vstack((s1_data, np.vstack((int_data, s2_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used only for t-sne\n",
    "\n",
    "# Feature scaling and mean normalization.\n",
    "# This can be used only for t-SNE, but is not strictly required.\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    average = np.mean(data[:,i])\n",
    "    stddev = np.std(data[:,i])\n",
    "    for j in range(data.shape[0]):\n",
    "        data[j,i] = np.around((data[j,i]-average)/stddev, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE dimensionality reduction\n",
    "\n",
    "X_embedded = utils.TSNE_dim_reduction(data, perp=50, components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For whole dataset\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "agn_classes = ['Type 1', 'Intermediate', 'Type 2']\n",
    "\n",
    "scatter = plt.scatter(X_embedded[:,0], X_embedded[:,1], c=data_labels, cmap='plasma', alpha=0.5,\n",
    "                      marker='o', s=70)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=agn_classes)\n",
    "\n",
    "# Save figure\n",
    "#plt.savefig('tsne_figures/tSNE_perp50_complete_dataset.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 3.3]\n",
    "\n",
    "**SVM classification over cembedded components from t-SNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing training, validation and test sets for data embedded with t-SNE\n",
    "\n",
    "m_test = (len(X_embedded)*20)/100\n",
    "m_validation = int(((len(X_embedded) - m_test)*20)/100)\n",
    "m_train = int(len(X_embedded) - m_test - m_validation)\n",
    "\n",
    "# random permutation\n",
    "permutation = np.random.permutation(X_embedded.shape[0])\n",
    "\n",
    "X_embedded = X_embedded[permutation]\n",
    "data_labels = data_labels[permutation]\n",
    "\n",
    "# features\n",
    "X_train = X_embedded[:m_train]\n",
    "X_validation = X_embedded[m_train:(m_validation+m_train)]\n",
    "X_test = X_embedded[(m_validation+m_train):]\n",
    "\n",
    "# labels\n",
    "y_train = data_labels[:m_train]\n",
    "y_validation = data_labels[m_train:(m_validation+m_train)]\n",
    "y_test = data_labels[(m_validation+m_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if every label is present in the training set\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rbf' kernel\n",
    "con_mat, norm_con_mat, SVM_clf_rbf_emb = utils.SVM_clf(X_train, y_train, X_validation, y_validation,\n",
    "                                                       clf_C=37.07880344704095,\n",
    "                                                       clf_gamma=0.005222946704501404, clf_kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SECTION 4]\n",
    "\n",
    "**Contour plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data and labels for contour plots\n",
    "df = pd.read_csv('/home/tobia/PycharmProjects/AGN_spectra/table_data_final.csv')\n",
    "data = df.loc[:, df.columns != 'labels']\n",
    "data_labels = df['labels']\n",
    "columns_wave = df.columns[:-1]\n",
    "\n",
    "# converts data and labels pandasdataframe into numpy arrays\n",
    "data = data.to_numpy()\n",
    "data_labels = data_labels.to_numpy()\n",
    "\n",
    "# check number of samples for every label\n",
    "sample_labels, sample_freqs = np.unique(data_labels, return_counts=True)\n",
    "print(\"Labels in dataset: \", sample_labels)\n",
    "print(\"Frequencies in dataset: \", sample_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used only for t-sne\n",
    "\n",
    "# Feature scaling and mean normalization. WRONG implementation, allows information leaks in classification.\n",
    "# This can be used only for t-SNE, but is not strictly required.\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    average = np.mean(data[:,i])\n",
    "    stddev = np.std(data[:,i])\n",
    "    for j in range(data.shape[0]):\n",
    "        data[j,i] = np.around((data[j,i]-average)/stddev, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour plot of rbf SVM over embedded features from t-SNE\n",
    "\n",
    "X = data  \n",
    "y = data_labels\n",
    "\n",
    "agn_classes = ['Type 1', 'Type 2', 'Intermediate']\n",
    "\n",
    "Xreduced = utils.TSNE_dim_reduction(data, data_labels, perp=50, components=2)\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "model = svm.SVC(kernel='rbf', C=37.07880344704095, gamma=0.005222946704501404,\n",
    "                class_weight='balanced', probability=True)\n",
    "clf = model.fit(Xreduced, y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# title for the plots\n",
    "title = ('Decision surface of rbf SVC')\n",
    "# Set-up grid for plotting.\n",
    "X0, X1 = Xreduced[:, 0], Xreduced[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "ax.set_ylabel('Embedded2')\n",
    "ax.set_xlabel('Embedded1')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title('Decison surface using t-SNE embedded features')\n",
    "ax.legend(handles=scatter.legend_elements()[0], labels=agn_classes)\n",
    "#plt.savefig('test_svm_contours.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
